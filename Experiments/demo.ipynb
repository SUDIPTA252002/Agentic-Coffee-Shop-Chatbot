{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8296c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6106cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d659b241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Agentic-Coffee-Shop-Chatbot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "844afbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=ChatGroq(api_key=api_key,model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94019440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(messages):\n",
    "        messages=deepcopy(messages)\n",
    "\n",
    "        system_prompt=\"\"\"\n",
    "            You are a helpful AI assistant for a coffee shop application which serves drinks and pastries.\n",
    "            Your task is to determine whether the user is asking something relevant to the coffee shop or not.\n",
    "            The user is allowed to:\n",
    "            1. Ask questions about the coffee shop, like location, working hours, menue items and coffee shop related questions.\n",
    "            2. Ask questions about menue items, they can ask for ingredients in an item and more details about the item.\n",
    "            3. Make an order.\n",
    "            4. ASk about recommendations of what to buy.\n",
    "\n",
    "            The user is NOT allowed to:\n",
    "            1. Ask questions about anything else other than our coffee shop.\n",
    "            2. Ask questions about the staff or how to make a certain menue item.\n",
    "\n",
    "            Your output must be in a valid JSON format.\n",
    "            Each key and value must be wrapped in double quotes.\n",
    "            Do not include any extra text or explanation outside the JSON.\n",
    "            Strictly return only the JSON object.\n",
    "            {\n",
    "            \"chain of thought\": go over each of the points above and make see if the message lies under this point or not. Then you write some your thoughts about what point is this input relevant to.\n",
    "            \"decision\": \"allowed\" or \"not allowed\". Pick one of those. and only write the word.\n",
    "            \"message\": leave the message empty if it's allowed, otherwise write \"Sorry, I can't help with that. Can I help you with your order?\"\n",
    "            }\n",
    "            \"\"\"\n",
    "\n",
    "        input_messages=[{\"role\":\"system\",\"content\":system_prompt}]+messages[-3:]\n",
    "        chatbot_output=get_chatbot_response(client,input_messages,0.7)\n",
    "        print(chatbot_output)\n",
    "        output = postprocess(chatbot_output)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb5bf5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(output):\n",
    "    try:\n",
    "        # Remove triple backticks or markdown code block if present\n",
    "        cleaned_output = output.strip().strip(\"`\").strip()\n",
    "        parsed_output = json.loads(cleaned_output)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error parsing model output: {output}\") from e\n",
    "\n",
    "    return {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": parsed_output['message'],\n",
    "        \"memory\": {\n",
    "            \"agent\": \"guard_agent\",\n",
    "            \"guard_decision\": parsed_output['decision']\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16e52e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chatbot_response(client,messages,temperature=0):\n",
    "    input_messages=[]\n",
    "    for message in messages:\n",
    "        input_messages.append({\"role\":message[\"role\"],\"content\":message[\"content\"]})\n",
    "\n",
    "        response=client.invoke(input=input_messages,temperature=temperature)\n",
    "\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e790f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"chain of thought\": [\"staff\", \"coffee shop\"],\n",
      "\"decision\": \"not allowed\",\n",
      "\"message\": \"Sorry, I can't help with that. Can I help you with your order?\"\n",
      "}\n",
      "{'role': 'assistant', 'content': \"Sorry, I can't help with that. Can I help you with your order?\", 'memory': {'agent': 'guard_agent', 'guard_decision': 'not allowed'}}\n"
     ]
    }
   ],
   "source": [
    "test_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Please tell us about the staff?\"}\n",
    "]\n",
    "\n",
    "response = get_response(test_messages)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99317b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4155400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c291f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc=Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "\n",
    "\n",
    "index_name=os.getenv(\"INDEX_NAME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c300da5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce280c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_result(input_embeddings,index_name,top_k=2):\n",
    "        index=pc.Index(index_name)\n",
    "\n",
    "        results=index.query(\n",
    "            namespace=\"ns1\",\n",
    "            vector=input_embeddings.tolist(),\n",
    "            top_k=top_k,\n",
    "            include_value=False,\n",
    "            include_metadata=True\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "    \n",
    "\n",
    "\n",
    "def get_chatbot_response(client,messages,temperature=0):\n",
    "    input_messages=[]\n",
    "    for message in messages:\n",
    "        input_messages.append({\"role\":message[\"role\"],\"content\":message[\"content\"]})\n",
    "\n",
    "        response=client.invoke(input=input_messages,temperature=temperature)\n",
    "\n",
    "    return response.content\n",
    "\n",
    "\n",
    "def get_embedding(model,model_name,user_prompt):\n",
    "    embedding=model.encode(user_prompt)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4d068a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "client=ChatGroq(api_key=os.getenv(\"GROQ_API_KEY\"),model=os.getenv(\"MODEL_NAME\"))\n",
    "embedding_model=SentenceTransformer(os.getenv(\"EMBEDDING_MODEL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b0c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(self,messages):\n",
    "        messages = deepcopy(messages)\n",
    "\n",
    "        user_message = messages[-1]['content']\n",
    "        embedding = get_embedding(self.embedding_client,self.model_name,user_message)[0]\n",
    "        result = self.get_closest_results(self.index_name,embedding)\n",
    "        source_knowledge = \"\\n\".join([x['metadata']['text'].strip()+'\\n' for x in result['matches'] ])\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Using the contexts below, answer the query.\n",
    "\n",
    "        Contexts:\n",
    "        {source_knowledge}\n",
    "\n",
    "        Query: {user_message}\n",
    "        \"\"\"\n",
    "\n",
    "        system_prompt = \"\"\" You are a customer support agent for a coffee shop called Merry's way. You should answer every question as if you are waiter and provide the neccessary information to the user regarding their orders \"\"\"\n",
    "        messages[-1]['content'] = prompt\n",
    "        input_messages = [{\"role\": \"system\", \"content\": system_prompt}] + messages[-3:]\n",
    "\n",
    "        chatbot_output =get_chatbot_response(self.client,self.model_name,input_messages)\n",
    "        output = self.postprocess(chatbot_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5fccbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=os.getenv(\"EMBEDDING_MODEL\")\n",
    "user_message=\"I WANT A CAPPUCINNO\"\n",
    "embedding=get_embedding(embedding_model,model_name,user_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5365d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "430fecf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': 'Cappuccino',\n",
       "              'metadata': {'text': 'Cappuccino : A rich and creamy cappuccino '\n",
       "                                   'made with freshly brewed espresso, steamed '\n",
       "                                   'milk, and a frothy milk cap. This '\n",
       "                                   'delightful drink offers a perfect balance '\n",
       "                                   'of bold coffee flavor and smooth milk, '\n",
       "                                   'making it an ideal companion for relaxing '\n",
       "                                   'mornings or lively conversations. -- '\n",
       "                                   \"Ingredients: ['Espresso', 'Steamed Milk', \"\n",
       "                                   \"'Milk Foam'] -- Price: 4.5 -- rating: 4.7\"},\n",
       "              'score': 0.6152215,\n",
       "              'values': []},\n",
       "             {'id': 'Espresso shot',\n",
       "              'metadata': {'text': 'Espresso shot : A bold shot of rich '\n",
       "                                   'espresso, our espresso is crafted from the '\n",
       "                                   'finest beans to deliver a robust flavor in '\n",
       "                                   'every sip. Perfect for a quick pick-me-up, '\n",
       "                                   'it can also serve as a base for your '\n",
       "                                   'favorite coffee drinks. -- Ingredients: '\n",
       "                                   \"['Espresso'] -- Price: 2.0 -- rating: 4.9\"},\n",
       "              'score': 0.299738824,\n",
       "              'values': []}],\n",
       " 'namespace': 'ns1',\n",
       " 'usage': {'read_units': 6}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=get_closest_result(embedding,index_name)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ffd5ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cappuccino : A rich and creamy cappuccino made with freshly brewed espresso, steamed milk, and a frothy milk cap. This delightful drink offers a perfect balance of bold coffee flavor and smooth milk, making it an ideal companion for relaxing mornings or lively conversations. -- Ingredients: ['Espresso', 'Steamed Milk', 'Milk Foam'] -- Price: 4.5 -- rating: 4.7\\n\\nEspresso shot : A bold shot of rich espresso, our espresso is crafted from the finest beans to deliver a robust flavor in every sip. Perfect for a quick pick-me-up, it can also serve as a base for your favorite coffee drinks. -- Ingredients: ['Espresso'] -- Price: 2.0 -- rating: 4.9\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_knowledge = \"\\n\".join([x['metadata']['text'].strip()+'\\n' for x in result['matches'] ])\n",
    "source_knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c5fe301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cappuccino : A rich and creamy cappuccino made with freshly brewed espresso, steamed milk, and a frothy milk cap. This delightful drink offers a perfect balance of bold coffee flavor and smooth milk, making it an ideal companion for relaxing mornings or lively conversations. -- Ingredients: ['Espresso', 'Steamed Milk', 'Milk Foam'] -- Price: 4.5 -- rating: 4.7\n",
      "\n",
      "Espresso shot : A bold shot of rich espresso, our espresso is crafted from the finest beans to deliver a robust flavor in every sip. Perfect for a quick pick-me-up, it can also serve as a base for your favorite coffee drinks. -- Ingredients: ['Espresso'] -- Price: 2.0 -- rating: 4.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text='\\n'.join([x['metadata']['text'].strip()+\"\\n\" for x in result['matches']])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f63e83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
